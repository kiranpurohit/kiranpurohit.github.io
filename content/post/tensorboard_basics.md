---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "TensorBoard Basics"
subtitle: ""
summary: "Visualing Tensorflow Models"
authors: []
tags: ["TensorBoard", "Tensorflow", "Python", "Deep learning", "Neural Networks"]
categories: ["Deep Learning"]
date: 2017-11-08T15:09:44+05:30
lastmod: 2017-11-08T15:09:44+05:30
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
# projects: []
---
## What is TensorBoard?

TensorBoard is a module of Tensorflow that provides a suite of visualisation tools that help in understanding, debugging and optimize the model created in Tensorflow.

## Installing TensorBoard

TensorBoard is installed along with Tensorflow.
It can also be installed as a standalone software from [Standalone TensorBoard](https://github.com/dmlc/tensorboard)

## Key Concepts

TensorBoard works by reading summary data from Tensorflow event files which is generated by tensorflow.

Tensorflow creates a computational graph of the neural network model implemented.This model is then stored as a graph using the **summary** method.The name field in the Tensorflow **variables**, **placeholders**, **operations**, and **name_scopes** are used to annotate the nodes in the graph. These graphs are written to files and stored in a directory indicated in the **summary.FileWriter** method.We can select which nodes to be included in the graph using the **summary.merge** method. In order to select all the nodes to be included in the graph by using the **summary.merge_all** method.This summary (in the form of a protocol buffer) is added to the event file using the **add_summary** method.

```python

#Although the model in this code-segment will not converge, 
#this is just to show how tensorflow creates and saves summaries 
#in event files.
import tensorflow as tf
import numpy as np
N = 5
x = tf.placeholder(tf.float32, shape=[N,1],name='X') 
y = tf.placeholder(tf.float32, shape=[N,N],name='y') 
with tf.name_scope('fc_layer'):
    W = tf.Variable(tf.truncated_normal([1,N], stddev=0.1), name='W')
    b = tf.Variable(tf.constant(0.1,shape=[N]),name='b')
    tf.summary.histogram('weights',W) #values of W will be shown as a histogram plot
    tf.summary.histogram('biases',b) #values of W will be shown as a histogram plot
    y_ = tf.matmul(x,W) + b
with tf.name_scope('loss_func'):    
    
    tf.summary.scalar('loss',0.05)


sess = tf.Session()
merged_summary = tf.summary.merge_all()
writer = tf.summary.FileWriter("./graphs/", graph=sess.graph)
sess.run(tf.global_variables_initializer())
s = sess.run(merged_summary,feed_dict={x:np.ones((N,1)),y:np.ones((N,N))})
i = 1  
writer.add_summary(s,i)
```python

## Running TensorBoard

Now that the event files have been created and stored in the directory[./graphs], running tensorboard with logdir pointing to the directory where the event files have been stored will give us a visualization of the model in the web browser.
```python
tensorboard --logdir=./graphs
```