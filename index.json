[{"authors":["admin"],"categories":null,"content":"I am currently pursuing my Ph.D. in the Department of Computer Science and Engineering at IIT Kharagpur, under the supervision of Prof. Sourangshu Bhattacharya. I am also a member of the Complex Networks Research Group.\nResearch - I am broadly interested in Machine Learning, with specific interests in Scalability, Explainability and Data-centric AI. I have applied these techniques on problems in Computer Vision and Natural Language Processing. My research involves subset selection for efficient and robust deep learning. I would be happy to talk about recent advancements around LLMs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://kiranpurohit.github.io/author/kiran-purohit/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kiran-purohit/","section":"authors","summary":"I am currently pursuing my Ph.D. in the Department of Computer Science and Engineering at IIT Kharagpur, under the supervision of Prof. Sourangshu Bhattacharya. I am also a member of the Complex Networks Research Group.","tags":null,"title":"Kiran Purohit","type":"authors"},{"authors":["Kiran Purohit"],"categories":[],"content":"02/2025: Invited to attend ACM Pingala Interactions in Computing (PIC) 2025 in India.\n","date":1737504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1737504000,"objectID":"7ac75fe3fac1227eb1231cfa30648a04","permalink":"https://kiranpurohit.github.io/news/2025_pingala/","publishdate":"2025-01-22T00:00:00Z","relpermalink":"/news/2025_pingala/","section":"news","summary":"02/2025: Invited to attend ACM Pingala Interactions in Computing (PIC) 2025 in India.","tags":[],"title":"[Feb 2025] Invited to attend ACM Pingala Interactions in Computing (PIC) 2025.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"01/2025: Invited to attend Google DeepMind Research Symposium 2025 in India.\n","date":1736208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736208000,"objectID":"3b71d229b6470a0105d22bfe894a9eb2","permalink":"https://kiranpurohit.github.io/news/2025_google/","publishdate":"2025-01-07T00:00:00Z","relpermalink":"/news/2025_google/","section":"news","summary":"01/2025: Invited to attend Google DeepMind Research Symposium 2025 in India.","tags":[],"title":"[Jan 2025] Invited to attend Google DeepMind Research Symposium 2025.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"11/2024: Invited to attend Amazon Research Days (ARD 2024) in India.\n","date":1732665600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1732665600,"objectID":"713ecfaaa622045fb682c7048b9b110d","permalink":"https://kiranpurohit.github.io/news/2024_ard/","publishdate":"2024-11-27T00:00:00Z","relpermalink":"/news/2024_ard/","section":"news","summary":"11/2024: Invited to attend Amazon Research Days (ARD 2024) in India.","tags":[],"title":"[Nov 2024] Invited to attend Amazon Research Days (ARD 2024) in India.","type":"news"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1731542400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731542400,"objectID":"7da95cd620df6ef4f7f8258045158092","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_6/","publishdate":"2024-11-14T00:00:00Z","relpermalink":"/talk/cnerg_rg_6/","section":"talk","summary":"Retrieval-based language models (LMs) have shown impressive performance on diverse NLP tasks. In this tutorial, we will provide a comprehensive and coherent overview of recent advances in retrieval-based LMs. We will start by providing preliminaries covering the foundation of LMs (e.g., masked LMs, autoregressive LMs) and retrieval systems (e.g., nearest-neighbor search). We will then detail recent progress in retrieval-based models, focusing on their model architectures and learning approaches. Finally, we will show how retrieval-based LMs are adapted to downstream applications, and extended to multilingual and multi-modal settings. Finally, we will use an exercise to showcase the effectiveness of retrieval-based LMs.","tags":null,"title":"Retrieval-based Language Models and Applications @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1731369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731369600,"objectID":"48a082040fda91214dfc60905d7362fc","permalink":"https://kiranpurohit.github.io/talk/emnlp24/","publishdate":"2024-11-12T00:00:00Z","relpermalink":"/talk/emnlp24/","section":"talk","summary":"Answering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task. Recent advances in large language models (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire proficiency in a specific task using only a few demonstration samples (exemplars). A critical challenge in ICL is the selection of optimal exemplars, which can be either task-specific (static) or test-example-specific (dynamic). Static exemplars provide faster inference times and increased robustness across a distribution of test examples. In this paper, we propose an algorithm for static exemplar subset selection for complex reasoning tasks. We introduce EXPLORA, a novel exploration method designed to estimate the parameters of the scoring function, which evaluates exemplar subsets without incorporating confidence information. EXPLORA significantly reduces the number of LLM calls to ~11% of those required by state-of-the-art methods and achieves a substantial performance improvement of 12.24%. We open-source our code and data (https://github.com/kiranpurohit/EXPLORA).","tags":null,"title":"EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning @EMNLP 2024","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1729728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729728000,"objectID":"01266ee2e66a139c580b9cc3c0563aff","permalink":"https://kiranpurohit.github.io/talk/ecai24/","publishdate":"2024-10-24T00:00:00Z","relpermalink":"/talk/ecai24/","section":"talk","summary":"Federated Learning systems are increasingly subjected to a multitude of model poisoning attacks from clients. Among these, edge-case attacks that target a small fraction of the input space are nearly impossible to detect using existing defenses, leading to a high attack success rate. We propose an effective defense using an external defense dataset, which provides information about the attack target. The defense dataset contains a mix of poisoned and clean examples, with only a few known to be clean. The proposed method, DataDefense, uses this dataset to learn a poisoned data detector model which marks each example in the defense dataset as poisoned or clean. It also learns a client importance model that estimates the probability of a client update being malicious. The global model is then updated as a weighted average of the client models' updates. The poisoned data detector and the client importance model parameters are updated using an alternating minimization strategy over the Federated Learning rounds. Extensive experiments on standard attack scenarios demonstrate that DataDefense can defend against model poisoning attacks where other state-of-the-art defenses fail. In particular, DataDefense is able to reduce the attack success rate by at least ~ 40% on standard attack setups and by more than 80% on some setups. Furthermore, DataDefense requires very few defense examples (as few as five) to achieve a near-optimal reduction in attack success rate.","tags":null,"title":"A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning @ECAI 2024","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"09/2024: Won second price at IBM Maitreyee Research Showcase 2024.\n","date":1726876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726876800,"objectID":"fd2539bd5a31dae0e109776467bbb245","permalink":"https://kiranpurohit.github.io/news/2024_ibm/","publishdate":"2024-09-21T00:00:00Z","relpermalink":"/news/2024_ibm/","section":"news","summary":"09/2024: Won second price at IBM Maitreyee Research Showcase 2024.","tags":[],"title":"[Sep 2024] Won second price at IBM Maitreyee Research Showcase 2024.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"09/2024: EMNLP 2024 paper on EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning.\n","date":1726358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726358400,"objectID":"2b96f2f22a676bab0b9a0f4899966fbf","permalink":"https://kiranpurohit.github.io/news/2024_emnlp/","publishdate":"2024-09-15T00:00:00Z","relpermalink":"/news/2024_emnlp/","section":"news","summary":"09/2024: EMNLP 2024 paper on EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning.","tags":[],"title":"[Sep 2024] Paper on EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning accepted at (EMNLP 2024).","type":"news"},{"authors":["Kiran Purohit","Venktesh V","Raghuram Devalla","Krishna Mohan Yerragorla","Sourangshu Bhattacharya","Avishek Anand"],"categories":null,"content":"","date":1726358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726358400,"objectID":"34111285b72b3b74f23216870aa9610f","permalink":"https://kiranpurohit.github.io/publication/emnlp24/","publishdate":"2024-09-15T00:00:00Z","relpermalink":"/publication/emnlp24/","section":"publication","summary":"Answering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task. Recent advances in large language models (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire proficiency in a specific task using only a few demonstration samples (exemplars). A critical challenge in ICL is the selection of effective exemplars, which can be either task-specific (static) or test-example-specific (dynamic). Static exemplars provide faster inference times and increased robustness across a distribution of test examples. In this paper, we propose an algorithm for static exemplar subset selection for complex reasoning tasks. We introduce EXPLORA, a novel exploration method designed to estimate the parameters of the scoring function, which evaluates exemplar subsets without incorporating confidence information. EXPLORA significantly reduces the number of LLM calls to ~11% of those required by state-of-the-art methods and achieves a substantial performance improvement of 12.24%. We open-source our code and data (https://github.com/kiranpurohit/EXPLORA).","tags":null,"title":"EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning","type":"publication"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1725926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725926400,"objectID":"df0f598bf125c61e554f4155caf35835","permalink":"https://kiranpurohit.github.io/talk/ibm24/","publishdate":"2024-09-10T00:00:00Z","relpermalink":"/talk/ibm24/","section":"talk","summary":"Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. We propose a simple and efficient technique for whole-network pruning.\nAnswering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task. Recent advances in large language models (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire proficiency in a specific task using only a few demonstration samples (exemplars). A critical challenge in ICL is the selection of optimal exemplars, which can be either task-specific (static) or test-example-specific (dynamic). Static exemplars provide faster inference times and increased robustness across a distribution of test examples. In this paper, we propose an algorithm for static exemplar subset selection for complex reasoning tasks. We introduce a novel exploration method designed to estimate the parameters of the scoring function, which evaluates exemplar subsets without incorporating confidence information.","tags":null,"title":"Application of Subset Selection in Efficient Machine Learning @IBM Maitreyee Research Showcase 2024","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1725235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1725235200,"objectID":"6e4333319844646627d2819aea8f11ef","permalink":"https://kiranpurohit.github.io/talk/tmlr24/","publishdate":"2024-09-02T00:00:00Z","relpermalink":"/talk/tmlr24/","section":"talk","summary":"Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. Hence there is a need for a simple and efficient technique for whole network pruning. This paper proposes a two-level hierarchical approach for whole-network filter pruning which is efficient and uses the classification loss as the final criterion. The lower-level algorithm (called filter-pruning) uses a sparse-approximation formulation based on linear approximation of filter weights. We explore two algorithms: orthogonal matching pursuit-based greedy selection and a greedy backward pruning approach. The backward pruning algorithm uses a novel closed-form error criterion for efficiently selecting the optimal filter at each stage, thus making the whole algorithm much faster. The higher-level algorithm (called layer-selection) greedily selects the best-pruned layer (pruning using the filter-selection algorithm) using a global pruning criterion. We propose algorithms for two different global-pruning criteria: (1) layerwise-relative error (HBGS), and (2) final classification error (HBGTS). Our suite of algorithms outperforms state-of-the-art pruning methods on ResNet18, ResNet32, ResNet56, VGG16, and ResNext101. Our method reduces the RAM requirement for ResNext101 from 7.6 GB to 1.5 GB and achieves a 94% reduction in FLOPS without losing accuracy on CIFAR-10.","tags":null,"title":"A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs @TMLR 2024","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"08/2024: TMLR 2024 paper on Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs.\n","date":1722902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722902400,"objectID":"60c8df1baa39c026a1d58196fe3bdcab","permalink":"https://kiranpurohit.github.io/news/2024_tmlr/","publishdate":"2024-08-06T00:00:00Z","relpermalink":"/news/2024_tmlr/","section":"news","summary":"08/2024: TMLR 2024 paper on Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs.","tags":[],"title":"[Aug 2024] Paper on A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs accepted at (TMLR 2024).","type":"news"},{"authors":["Kiran Purohit","Anurag Parvathgari","Sourangshu Bhattacharya"],"categories":null,"content":"","date":1722902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722902400,"objectID":"47b1f11e5e6c1bebe8151f5a76fea300","permalink":"https://kiranpurohit.github.io/publication/tmlr24/","publishdate":"2024-08-06T00:00:00Z","relpermalink":"/publication/tmlr24/","section":"publication","summary":"Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. Hence there is a need for a simple and efficient technique for whole network pruning. This paper proposes a two-level hierarchical approach for whole-network filter pruning which is efficient and uses the classification loss as the final criterion. The lower-level algorithm (called filter-pruning) uses a sparse-approximation formulation based on linear approximation of filter weights. We explore two algorithms: orthogonal matching pursuit-based greedy selection and a greedy backward pruning approach. The backward pruning algorithm uses a novel closed-form error criterion for efficiently selecting the optimal filter at each stage, thus making the whole algorithm much faster. The higher-level algorithm (called layer-selection) greedily selects the best-pruned layer (pruning using the filter-selection algorithm) using a global pruning criterion. We propose algorithms for two different global-pruning criteria: (1) layerwise-relative error (HBGS), and (2) final classification error (HBGTS). Our suite of algorithms outperforms state-of-the-art pruning methods on ResNet18, ResNet32, ResNet56, VGG16, and ResNext101. Our method reduces the RAM requirement for ResNext101 from 7.6 GB to 1.5 GB and achieves a 94% reduction in FLOPS without losing accuracy on CIFAR-10.","tags":null,"title":"A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs","type":"publication"},{"authors":["Kiran Purohit"],"categories":[],"content":"07/2024: ECAI 2024 paper on A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning.\n","date":1720051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720051200,"objectID":"47f1003b8abaa3fde21859e3eb33fc4b","permalink":"https://kiranpurohit.github.io/news/2024_ecai/","publishdate":"2024-07-04T00:00:00Z","relpermalink":"/news/2024_ecai/","section":"news","summary":"07/2024: ECAI 2024 paper on A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning.","tags":[],"title":"[Jul 2024] Paper on A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning accepted at (ECAI 2024).","type":"news"},{"authors":["Kiran Purohit","Soumi Das","Sourangshu Bhattacharya","Santu Rana"],"categories":null,"content":"","date":1720051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720051200,"objectID":"224eb7f9f084d8e1c2315e6258c10ce2","permalink":"https://kiranpurohit.github.io/publication/ecai24/","publishdate":"2024-07-04T00:00:00Z","relpermalink":"/publication/ecai24/","section":"publication","summary":"Federated Learning systems are increasingly subjected to a multitude of model poisoning attacks from clients. Among these, edge-case attacks that target a small fraction of the input space are nearly impossible to detect using existing defenses, leading to a high attack success rate. We propose an effective defense using an external defense dataset, which provides information about the attack target. The defense dataset contains a mix of poisoned and clean examples, with only a few known to be clean. The proposed method, DataDefense, uses this dataset to learn a poisoned data detector model which marks each example in the defense dataset as poisoned or clean. It also learns a client importance model that estimates the probability of a client update being malicious. The global model is then updated as a weighted average of the client models' updates. The poisoned data detector and the client importance model parameters are updated using an alternating minimization strategy over the Federated Learning rounds. Extensive experiments on standard attack scenarios demonstrate that DataDefense can defend against model poisoning attacks where other state-of-the-art defenses fail. In particular, DataDefense is able to reduce the attack success rate by at least ~ 40% on standard attack setups and by more than 80% on some setups. Furthermore, DataDefense requires very few defense examples (as few as five) to achieve a near-optimal reduction in attack success rate.","tags":null,"title":"A Data-Driven Defense against Edge-case Model Poisoning Attacks on Federated Learning","type":"publication"},{"authors":["Kiran Purohit"],"categories":[],"content":"7/2024 - 09/2024: Teaching Assistant at AICTE QIP PG Certificate Programme for Core Engineering Faculty.\n","date":1719792000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719792000,"objectID":"022e07df54e37f48caddab2b3d7276ba","permalink":"https://kiranpurohit.github.io/news/2024_teaching_aicte/","publishdate":"2024-07-01T00:00:00Z","relpermalink":"/news/2024_teaching_aicte/","section":"news","summary":"7/2024 - 09/2024: Teaching Assistant at AICTE QIP PG Certificate Programme for Core Engineering Faculty.","tags":[],"title":"[Jul 2024] Selected as a Teaching Assistant at (AICTE QIP PG Certificate Programme) for Core Engineering Faculty.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"06/2024: Got selected for ACM India Grad Cohort 2024.\n","date":1719360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719360000,"objectID":"b657449646fafadc2387a87e4042d5ab","permalink":"https://kiranpurohit.github.io/news/2024_acm_grad_cohort/","publishdate":"2024-06-26T00:00:00Z","relpermalink":"/news/2024_acm_grad_cohort/","section":"news","summary":"06/2024: Got selected for ACM India Grad Cohort 2024.","tags":[],"title":"[Jun 2024] Got selected for (ACM India Grad Cohort 2024).","type":"news"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1705536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705536000,"objectID":"06fdcbaa535d721b38628913103ae48d","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_5/","publishdate":"2024-01-18T00:00:00Z","relpermalink":"/talk/cnerg_rg_5/","section":"talk","summary":"Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the difficulty of encoding a wealth of world knowledge in their parameters. This paper aims to understand LMs’ strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments on two open-domain entity-centric QA datasets: PopQA, our new dataset with 14k questions about long-tail entities, and EntityQuestions, a widely used open-domain QA dataset. We find that LMs struggle with less popular factual knowledge, and that retrieval augmentation helps significantly in these cases. Scaling, on the other hand, mainly improves memorization of popular knowledge, and fails to appreciably improve memorization of factual knowledge in the tail. Based on those findings, we devise a new method for retrieval-augmentation that improves performance and reduces inference costs by only retrieving non-parametric memories when necessary.","tags":null,"title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"01/2024: Got AI4ICPS Chanakya PhD Fellowship.\n","date":1704931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704931200,"objectID":"e9ccb72f196f5064ad18b92fce8d41be","permalink":"https://kiranpurohit.github.io/news/2024_chanakya/","publishdate":"2024-01-11T00:00:00Z","relpermalink":"/news/2024_chanakya/","section":"news","summary":"01/2024: Got AI4ICPS Chanakya PhD Fellowship.","tags":[],"title":"[Jan 2024] Got (AI4ICPS Chanakya PhD Fellowship).","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"12/2023 - 09/2024: Teaching Assistant at Virginia Tech - IIT Kharagpur Joint Certification Program In Business Analytics and AI.\n","date":1701388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701388800,"objectID":"07cf454f2424375c44f1121aaebecfc6","permalink":"https://kiranpurohit.github.io/news/2023_teaching_virginia-iitkgp/","publishdate":"2023-12-01T00:00:00Z","relpermalink":"/news/2023_teaching_virginia-iitkgp/","section":"news","summary":"12/2023 - 09/2024: Teaching Assistant at Virginia Tech - IIT Kharagpur Joint Certification Program In Business Analytics and AI.","tags":[],"title":"[Dec 2023] Selected as a Teaching Assistant at (Virginia Tech - IIT Kharagpur) Joint Certification Program In Business Analytics and AI.","type":"news"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1697068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697068800,"objectID":"5c1d334b969cc3c16121486567449b3f","permalink":"https://kiranpurohit.github.io/talk/cnerg_mini_retreat/","publishdate":"2023-10-12T00:00:00Z","relpermalink":"/talk/cnerg_mini_retreat/","section":"talk","summary":"The deeper and wider architectures of recent convolutional neural networks (CNN) are responsible for superior performance in computer vision tasks. However, they also come with an enormous model size and heavy computational cost. Filter pruning (FP) is one of the methods applied to CNNs for compression and acceleration.","tags":null,"title":"Scalable and Accurate Channel pruning @CNeRG Mini Retreat","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1686182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686182400,"objectID":"ad7fb780a670d2acc4be0c0370fa8a24","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_4/","publishdate":"2023-06-08T00:00:00Z","relpermalink":"/talk/cnerg_rg_4/","section":"talk","summary":"Pruning, the task of sparsifying deep neural networks, received increasing attention recently. Although state-of-the-art pruning methods extract highly sparse models, they neglect two main challenges: (1) the process of finding these sparse models is often very expensive; (2) unstructured pruning does not provide benefits in terms of GPU memory, training time, or carbon emissions. We propose Early Compression via Gradient Flow Preservation (EarlyCroP), which efficiently extracts state-of-the-art sparse models before or early in training addressing challenge (1), and can be applied in a structured manner addressing challenge (2). This enables us to train sparse networks on commodity GPUs whose dense versions would be too large, thereby saving costs and reducing hardware requirements. We empirically show that EarlyCroP outperforms a rich set of baselines for many tasks (incl. classification, regression) and domains (incl. computer vision, natural language processing, and reinforcment learning). EarlyCroP leads to accuracy comparable to dense training while outperforming pruning baselines.","tags":null,"title":"Winning the Lottery Ahead of Time: Efficient Early Network Pruning @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"12/2022: Attended Indian Symposium on Machine Learning (IndoML) by IIT Gandhinagar.\n","date":1671062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671062400,"objectID":"8d6b1c22abe94ccc7264b88a66a1f351","permalink":"https://kiranpurohit.github.io/news/2022_indoml/","publishdate":"2022-12-15T00:00:00Z","relpermalink":"/news/2022_indoml/","section":"news","summary":"12/2022: Attended Indian Symposium on Machine Learning (IndoML) by IIT Gandhinagar.","tags":[],"title":"[Dec 2022] Attended Indian Symposium on Machine Learning (IndoML 2022) by IIT Gandhinagar.","type":"news"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1668729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668729600,"objectID":"c8f5014afdb4d7751645c2f6d5287804","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_3/","publishdate":"2022-11-18T00:00:00Z","relpermalink":"/talk/cnerg_rg_3/","section":"talk","summary":"Deep learning has brought us tremendous achievements in many fields such as computer vision, natural language processing. In spite of the impeccable success, modern deep learning systems are still prone to adversaries. Let's talk in terms of computer vision. Consider an image of a bagel (X). A Deep learning-based image classifier is able to successfully recognize X as a bagel. Now consider another instance of the same image which is a slightly perturbed version of X. To the human eyes, it would still be a bagel but for that same image classifier, it can be presented as a grand piano. The focus of this tutorial is not just to survey different attack types but also how to employ them in practice, to look at various state-of-the-art pre-trained models, optimizers and test their susceptibility to these attacks, and then to employ the latest and best techniques to prevent adversarial attacks, thanks to the principles in adversarial learning. This tutorial also aims to provide a holistic and complementary overview of how the same adversarial technique can be used in totally different manners, for good and (unintentionally) for bad, so that AI researchers and developers can have a fresh perspective and some reflection on the induced impacts and responsibility. To make some concrete examples, generative adversarial networks (GANs) are capable of generating photo-realistic synthetic images; but the same techniques can be repurposed into troublesome tools such as Deepfake. On the other hand, adversarial attacks causing prediction evasion are often related to a trouble maker or a security outbreak, but the same techniques are used for improving model robustness and for novel applications, such as adversarial training, privacy-enhanced training, data augmentation, watermarking, and integrity testing, to name a few.","tags":null,"title":"Practical Adversarial Robustness in Deep Learning: Problems and Solutions @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1665705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665705600,"objectID":"8ab18b40b12dfc522183408eee9fdfe2","permalink":"https://kiranpurohit.github.io/talk/aimlsys22/","publishdate":"2022-10-14T00:00:00Z","relpermalink":"/talk/aimlsys22/","section":"talk","summary":"The deeper and wider architectures of recent convolutional neural networks (CNN) are responsible for superior performance in computer vision tasks. However, they also come with an enormous model size and heavy computational cost. Filter pruning (FP) is one of the methods applied to CNNs for compression and acceleration. Various techniques have been recently proposed for filter pruning. We address the limitation of the existing state-of-the-art method and motivate our setup. We develop a novel method for filter selection using sparse approximation of filter weights. We propose an orthogonal matching pursuit (OMP) based algorithm for filter pruning (called FP-OMP). We also propose FP-OMP Search, which address the problem of removal of uniform number of filters from all the layers of a network. FP-OMP Search performs a search over all the layers with a given batch size of filter removal. We evaluate both FP-OMP and FP-OMP Search on benchmark datasets using standard ResNet architectures. Experimental results indicate that FP-OMP Search consistently outperforms the baseline method (LRF) by nearly 0.5 − 3%. We demonstrate both empirically and visually, that FP-OMP Search prunes different number of filters from different layers. Further, timing profile experiments show that FP-OMP improves over the running time of LRF.","tags":null,"title":"Accurate and efficient channel pruning via orthogonal matching pursuit @AIMLSystems 2022","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1665705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665705600,"objectID":"6f1e7798540d90b53ebe364a22d427a6","permalink":"https://kiranpurohit.github.io/talk/aimlsys22_doctoral/","publishdate":"2022-10-14T00:00:00Z","relpermalink":"/talk/aimlsys22_doctoral/","section":"talk","summary":"Federated Learning has emerged as an important paradigm for training Machine Learning (ML) models. The key idea is that many clients own the data needed to train their local ML models, and share the local models with a master, which in turn shares the aggregated global model back with each of the clients. The federated averaging algorithm has been a mainstay of federated learning, due to its effectiveness, simplicity, and privacy preserving properties. However, they have been shown to be particularly vulnerable to model-poisoning attacks by one or more clients. Two particular properties of modern model-poisoning attacks make them virtually undetectable. Firstly, the model-replacement attacks proposed in, can offset the “correct” models contributed by many other clients, even under bounded-deviation constraints. Secondly, edge-case backdoor attacks, can manifest themselves on a very small subset of the input feature space. These factors lead Wang et al. to lead to the conclusion that no fixed defense rule can stop the backdoor attack on federated learning system","tags":null,"title":"LearnDefend: Learning to Defend against Backdoor Attacks on Federated Learning @AIMLSystems Doctoral Symposium 2022","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"09/2022: AIMLSystems 2022 paper on Accurate and Efficient Channel pruning via Orthogonal Matching Pursuit.\n","date":1662336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662336000,"objectID":"006864b18ec9cd80993b0889562b85f8","permalink":"https://kiranpurohit.github.io/news/2022_aiml/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/news/2022_aiml/","section":"news","summary":"09/2022: AIMLSystems 2022 paper on Accurate and Efficient Channel pruning via Orthogonal Matching Pursuit.","tags":[],"title":"[Sep 2022] Paper on Accurate and Efficient Channel pruning via Orthogonal Matching Pursuit accepted at (AIMLSystems 2022).","type":"news"},{"authors":["Kiran Purohit","Anurag Parvathgari","Soumi Das","Sourangshu Bhattacharya"],"categories":null,"content":"","date":1662336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662336000,"objectID":"611be641cfaf335780c6ce74b9df12d5","permalink":"https://kiranpurohit.github.io/publication/aimlsys22/","publishdate":"2022-09-05T00:00:00Z","relpermalink":"/publication/aimlsys22/","section":"publication","summary":"The deeper and wider architectures of recent convolutional neural networks (CNN) are responsible for superior performance in computer vision tasks. However, they also come with an enormous model size and heavy computational cost. Filter pruning (FP) is one of the methods applied to CNNs for compression and acceleration. Various techniques have been recently proposed for filter pruning. We address the limitation of the existing state-of-the-art method and motivate our setup. We develop a novel method for filter selection using sparse approximation of filter weights. We propose an orthogonal matching pursuit (OMP) based algorithm for filter pruning (called FP-OMP). We also propose FP-OMP Search, which address the problem of removal of uniform number of filters from all the layers of a network. FP-OMP Search performs a search over all the layers with a given batch size of filter removal. We evaluate both FP-OMP and FP-OMP Search on benchmark datasets using standard ResNet architectures. Experimental results indicate that FP-OMP Search consistently outperforms the baseline method (LRF) by nearly 0.5 − 3%. We demonstrate both empirically and visually, that FP-OMP Search prunes different number of filters from different layers. Further, timing profile experiments show that FP-OMP improves over the running time of LRF.","tags":null,"title":"Accurate and efficient channel pruning via orthogonal matching pursuit","type":"publication"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1651104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651104000,"objectID":"29642d0490522d951caf41d1945af5cd","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_2/","publishdate":"2022-04-28T00:00:00Z","relpermalink":"/talk/cnerg_rg_2/","section":"talk","summary":"For many users on social networks, one of the goals when broadcasting content is to reach a large audience. The probability of receiving reactions to a message differs for each user and depends on various factors, such as location, daily and weekly behavior patterns and the visibility of the message. While previous work has focused on overall network dynamics and message flow cascades, the problem of recommending personalized posting times has remained an underexplored topic of research. In this study, we formulate a when-to-post problem, where the objective is to find the best times for a user to post on social networks in order to maximize the probability of audience responses. To understand the complexity of the problem, we examine user behavior in terms of post-to-reaction times, and compare cross-network and cross-city weekly reaction behavior for users in different cities, on both Twitter and Facebook. We perform this analysis on over a billion posted messages and observed reactions, and propose multiple approaches for generating personalized posting schedules. We empirically assess these schedules on a sampled user set of 0.5 million active users and more than 25 million messages observed over a 56 day period. We show that users see a reaction gain of up to 17% on Facebook and 4% on Twitter when the recommended posting times are used. We open the dataset used in this study, which includes timestamps for over 144 million posts and over 1.1 billion reactions. The personalized schedules derived here are used in a fully deployed production system to recommend posting times for millions of users every day.","tags":null,"title":"When-To-Post on Social Networks @CNeRG Reading Group @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":[],"content":"12/2021: Attended ATAL, AICTE FDP on Explainable Artificial Intelligence and Future by IIIT Kota.\n","date":1640217600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640217600,"objectID":"1913ec4e067f2d9c387616d31e5afc56","permalink":"https://kiranpurohit.github.io/news/2021_atal/","publishdate":"2021-12-23T00:00:00Z","relpermalink":"/news/2021_atal/","section":"news","summary":"12/2021: Attended ATAL, AICTE FDP on Explainable Artificial Intelligence and Future by IIIT Kota.","tags":[],"title":"[Dec 2021] Attended ATAL, (AICTE FDP) on Explainable Artificial Intelligence and Future by IIIT Kota.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"12/2021: Attended Indian Symposium on Machine Learning (IndoML) by IIT Gandhinagar.\n","date":1639612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639612800,"objectID":"1cb2f7f590e7b92475efb80047d2f790","permalink":"https://kiranpurohit.github.io/news/2021_indoml/","publishdate":"2021-12-16T00:00:00Z","relpermalink":"/news/2021_indoml/","section":"news","summary":"12/2021: Attended Indian Symposium on Machine Learning (IndoML) by IIT Gandhinagar.","tags":[],"title":"[Dec 2021] Attended Indian Symposium on Machine Learning (IndoML 2021) by IIT Gandhinagar.","type":"news"},{"authors":["Kiran Purohit"],"categories":[],"content":"11/2021: Invited to attend Amazon Research Days in India.\n","date":1637107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637107200,"objectID":"d30e7b4366c4854a9927b9e4b2181563","permalink":"https://kiranpurohit.github.io/news/2021_ard/","publishdate":"2021-11-17T00:00:00Z","relpermalink":"/news/2021_ard/","section":"news","summary":"11/2021: Invited to attend Amazon Research Days in India.","tags":[],"title":"[Nov 2021] Invited to attend Amazon Research Days (ARD 2021) in India.","type":"news"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1631145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631145600,"objectID":"bcd6e7140a35db6ad458a2b973e1dda4","permalink":"https://kiranpurohit.github.io/talk/cnerg_rg_1/","publishdate":"2021-09-09T00:00:00Z","relpermalink":"/talk/cnerg_rg_1/","section":"talk","summary":"The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations, 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics, 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format, 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics, 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.","tags":null,"title":"SummEval: Re-evaluating Summarization Evaluation @CNeRG Reading Group","type":"talk"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1614902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614902400,"objectID":"8c63cb4dcf21dd6bd57d098be6afd7da","permalink":"https://kiranpurohit.github.io/talk/icmc21/","publishdate":"2021-03-05T00:00:00Z","relpermalink":"/talk/icmc21/","section":"talk","summary":"COVID-19 is a deadly and highly infectious pneumonia type disease. RT-PCR is a proven testing methodology for the detection of coronavirus infection in spite of having a lengthy testing time. Sometimes, it gives false-positive results more than the desired rates. To support the conventional RT-PCR methodology or testing independently without RC-PCR methodology for correct clinical diagnosis, COVID-19 testing can be acquired with images of X-Ray and CT Scan of a person. This image-based analysis will make a radical change in the detection of coronavirus in the human body with negligible false-negative and false-positive results. For the detection of COVID-19 in CT Scan and X-Ray images of coronavirus suspected individuals, this paper uses a multi-image augmented Convolutional Neural Network (CNN). For training the CNN model, multi-image augmentation utilizes discontinuity information acquired from the edged images to increase the meaningful examples. With this method, the proposed model exhibits a higher classification accuracy of around 98.97% for X-Ray and 95.38% for CT Scan images. Using multi-image augmentation, X-Ray images achieve a specificity of 98.88% and a sensitivity of 99.07% whereas a specificity of 95.98% and sensitivity of 94.78% are achieved in CT Scan images. The experimental results are also compared with VGG-16 and ResNet-50 models. The evaluation has been performed on publicly available databases comprising chest images of both X-Ray and CT Scan.","tags":null,"title":"COVID-19 Detection on Chest X-Ray and CT Scan Images Using Multi-image Augmented Deep Learning Model @ICMC 2021","type":"talk"},{"authors":["Kiran Purohit","Abhishek Kesarwani","Dakshina Ranjan Kisku","Mamata Dalui"],"categories":null,"content":"","date":1614816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614816000,"objectID":"8dd0e0572fc21c8f4f289a94adbb0e65","permalink":"https://kiranpurohit.github.io/publication/icmc21/","publishdate":"2021-03-04T00:00:00Z","relpermalink":"/publication/icmc21/","section":"publication","summary":"COVID-19 is a deadly and highly infectious pneumonia type disease. RT-PCR is a proven testing methodology for the detection of coronavirus infection in spite of having a lengthy testing time. Sometimes, it gives false-positive results more than the desired rates. To support the conventional RT-PCR methodology or testing independently without RC-PCR methodology for correct clinical diagnosis, COVID-19 testing can be acquired with images of X-Ray and CT Scan of a person. This image-based analysis will make a radical change in the detection of coronavirus in the human body with negligible false-negative and false-positive results. For the detection of COVID-19 in CT Scan and X-Ray images of coronavirus suspected individuals, this paper uses a multi-image augmented Convolutional Neural Network (CNN). For training the CNN model, multi-image augmentation utilizes discontinuity information acquired from the edged images to increase the meaningful examples. With this method, the proposed model exhibits a higher classification accuracy of around 98.97% for X-Ray and 95.38% for CT Scan images. Using multi-image augmentation, X-Ray images achieve a specificity of 98.88% and a sensitivity of 99.07% whereas a specificity of 95.98% and sensitivity of 94.78% are achieved in CT Scan images. The experimental results are also compared with VGG-16 and ResNet-50 models. The evaluation has been performed on publicly available databases comprising chest images of both X-Ray and CT Scan.","tags":null,"title":"COVID-19 Detection on Chest X-Ray and CT Scan Images Using Multi-image Augmented Deep Learning Model","type":"publication"},{"authors":["Abhishek Kesarwani","Kiran Purohit","Mamata Dalui","Dakshina Ranjan Kisku"],"categories":null,"content":"","date":1600646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600646400,"objectID":"89ce80897b8b86001d0cd18bdb04576e","permalink":"https://kiranpurohit.github.io/publication/aspcon20/","publishdate":"2020-09-21T00:00:00Z","relpermalink":"/publication/aspcon20/","section":"publication","summary":"Unlike image restoration, image enhancement techniques are found to be subjective in nature as the appearance of an output image depends upon human perception. Hence, it is very difficult to determine the appropriateness of image enhancement techniques including edge detection operators prior to an application. This paper makes use of regression models to determine the suitability of edge detection operators before operators to be executed. With the existing operators, a novel Hybrid technique is used in the evaluation. The Hybrid detector is designed by combining Canny and Sobel operators with the gradient of texton image. This approach estimates a model as an objective function to determine the degree of proximity or suitability of edge detection operators under regression constraints on two publicly available databases, viz. the BSDS300 and the Multi-cue. The experimental results exhibit that the Hybrid edge detector outperforms other operators for measuring the proximity for appropriateness.","tags":null,"title":"Measuring the Degree of Suitability of Edge Detection Operators Prior to an Application","type":"publication"},{"authors":["Kiran Purohit"],"categories":null,"content":"","date":1592611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592611200,"objectID":"274a63bb9b86c017f59c4c82de0347fc","permalink":"https://kiranpurohit.github.io/talk/mtech_thesis/","publishdate":"2020-06-20T00:00:00Z","relpermalink":"/talk/mtech_thesis/","section":"talk","summary":"Unlike image restoration, image enhancement techniques are found to be subjective in nature as the appropriateness of the appearance of output image depends upon human perception. Hence, it is very difficult to determine the appropriateness of the image enhancement techniques including edge detection prior to an application. This thesis makes use of regression models to determine the suitability of edge detection operators. With the existing operators, a novel Hybrid operator is used in the evaluation. The novel detector is made of combining Canny and Sobel operators with the gradient of the texton image. With this approach, an estimation model as an objective function is determined and further, it is used to determine the degree of proximity (suitability) of the edge operators on two publicly available databases, viz. the BSDS300 and the Multi-cue. The experimental results exhibit that the proposed edge detector outperforms other operators. Sharpening Filters can also be used for data augmentation in detecting Coronavirus using deep learning CNN model. Coronavirus is rapidly increasing and threatening the health of millions of humans. Clinical study shows that it affects the lungs. So, lung infections can be diagnosed with the help of X-Ray and CT Scan images. As deep learning is the most effective and reliable AI technique to classify the COVID-19 screening, we proposed a model which uses Convolutional Neural Network (CNN) fused with the image processing based data augmentation. This application makes use of multiple representations of the same X-Ray and CT scan images, produced through sharpening filters viz. Sobel, Prewitt, Roberts, Scharr, Laplacian, Canny, and Hybrid, are mixed up with visible X-Ray and CT scan images for training the convolutional neural network (CNN) based deep learning model. Our proposed AI application has been tested on publicly available databases of both chest X-Ray and CT Scan images.","tags":null,"title":"Some Applications of First and Second Order Derivative Operators in Machine Learning and Clinical Diagnosis @M.Tech Thesis, NIT Durgapur","type":"talk"},{"authors":[],"categories":["cpp to java cheatsheet"],"content":"Some differences between c++ and java:\n  Java compiled code is platform independent whereas c++ compiled code is platform dependent\n  Java interpreter reports the run-time error that caused the execution to halt unlike in c/c++ programs which may simply crash\n  c/c++ do not have strict sizes for the fundamental datatypes(varies from machine to machine) whereas Java defines strict sizes for their datatypes\n  Java has additional positive and negative zeros, positive and neagtive infinites and \u0026ldquo;nan\u0026rdquo;(not a number values)\n  c/c++ has functions while Java has methods.In c/c++ functions can be defined outside a class Java doesnot allow methods to be defined outside a class.\n  Unlike c++ arrays, Java arrays are objects.\n  Unlike c++, strings are immutable in Java.\n  While in c++ classes \u0026ldquo;public\u0026rdquo;, \u0026ldquo;private\u0026rdquo; and \u0026ldquo;protected\u0026rdquo; are labels , in Java they are modifiers. Each member has its own access modifier. Java also has a no-modifier(a.k.a package-private) option which makes the member visible only within its own package.\n  Unlike c++, Java method definitions do not have semicolon at the end of their closing brackets.\n  Java uses the \u0026ldquo;extends\u0026rdquo; keyword while inherting features of a class to specify the superclass.\n  Java does not support multiple inheritance but supports multiple interfaces.\n  Unlike c++ Java has interfaces which is a bit different from abstract class.\n  In Java superclass constructors are callled using the keyword \u0026ldquo;super\u0026rdquo;.\n  Unlike c++ Java has class hierarchy. The \u0026ldquo;Object\u0026rdquo; class is the root of this hierarchy. All classes are subclasses of this root class.\n  There are many other differences also but these basic differences will help you get your hands dirty with Java !! :) ","date":1588228264,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588228264,"objectID":"a678664911ba550e4a7a6a2446b2353e","permalink":"https://kiranpurohit.github.io/post/cpp_to_java/","publishdate":"2020-04-30T12:01:04+05:30","relpermalink":"/post/cpp_to_java/","section":"post","summary":"Some differences between c++ and java:\n  Java compiled code is platform independent whereas c++ compiled code is platform dependent\n  Java interpreter reports the run-time error that caused the execution to halt unlike in c/c++ programs which may simply crash","tags":["coding","C","CPP","Java"],"title":"From CPP to Java","type":"post"},{"authors":[],"categories":["statistics","mathematics","probability"],"content":"Sampling Theory Data scientists are required to draw conclusions about a group, a.k.a population from a few samples of it because getting the entire population is intractable. This process of drawing samples is called sampling. There are different kinds of sampling , few of which are:\n Random sampling Clustered sampling Stratified sampling Systematic sampling You can read about them over here The drawing of conclusions or inference about the population from the samples is called statistical inference.  In this section we will consider two different types of samples:\n Sampling with Replacement Sampling without Replacement  Random Sampling with Replacement As the name suggests, this is a type of sampling where each member of the population may be included more than once. It\u0026rsquo;s like picking a ball from an urn and then putting it back into the urn.\nRandom Sampling without Replacement In this type of sampling, each member of the population can be included atmost once. A similar example for this type of sampling would be picking a ball from the urn and not putting it back inside the urn.\nSampling statistics A quantity obtained from the sample for the purpose estimating a population parameter is called a sample statistic or briefly statistic. Mathematically, a sample statistic for a sample of size $n$ can be defined as a function of the random variables $ X_1, X_2,\u0026hellip;,X_n $ i.e., $ g(X_1, X_2,\u0026hellip;,X_n) $. The function $ g(X_1, X_2,\u0026hellip;,X_n) $ is another random variable whose values can be represented by $g(x_1, x_2,\u0026hellip;,x_n)$.\nMore info coming soon :-) Note: This chapter has sections taken from the book and Statistical Methods course offered at IIT Kharagpur Comments Please feel free to comment in the comment section below\n","date":1575469236,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575469236,"objectID":"22332816a05c1a5d7a947a4173a8eaa1","permalink":"https://kiranpurohit.github.io/post/stat-101/","publishdate":"2019-12-04T19:50:36+05:30","relpermalink":"/post/stat-101/","section":"post","summary":"Sampling Theory Data scientists are required to draw conclusions about a group, a.k.a population from a few samples of it because getting the entire population is intractable. This process of drawing samples is called sampling.","tags":["statistics","hypothesis testing","samples"],"title":"Stats 101","type":"post"},{"authors":[],"categories":["statistics","mathematics","probability"],"content":"Sampling Theory Data scientists are required to draw conclusions about a group, a.k.a population from a few samples of it because getting the entire population is intractable. This process of drawing samples is called sampling. There are different kinds of sampling , few of which are:\n Random sampling Clustered sampling Stratified sampling Systematic sampling You can read about them over here The drawing of conclusions or inference about the population from the samples is called statistical inference.  In this section we will consider two different types of samples:\n Sampling with Replacement Sampling without Replacement  Random Sampling with Replacement As the name suggests, this is a type of sampling where each member of the population may be included more than once. It\u0026rsquo;s like picking a ball from an urn and then putting it back into the urn.\nRandom Sampling without Replacement In this type of sampling, each member of the population can be included atmost once. A similar example for this type of sampling would be picking a ball from the urn and not putting it back inside the urn.\nSampling statistics A quantity obtained from the sample for the purpose estimating a population parameter is called a sample statistic or briefly statistic. Mathematically, a sample statistic for a sample of size $n$ can be defined as a function of the random variables $X_1, X_2,\u0026hellip;,X_n$ i.e., $g(X_1, X_2,\u0026hellip;,X_n)$. The function $g(X_1, X_2,\u0026hellip;,X_n)$ is another random variable whose values can be represented by $g(x_1, x_2,\u0026hellip;,x_n)$.\nSampling Distributions Note: This chapter has sections taken from the book and Statistical Methods course offered at IIT Kharagpur ","date":1572963636,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572963636,"objectID":"45f05b443e5b1616f78f9a5562f881bb","permalink":"https://kiranpurohit.github.io/post/sampling_theory_and_dist/","publishdate":"2019-11-05T19:50:36+05:30","relpermalink":"/post/sampling_theory_and_dist/","section":"post","summary":"Sampling Theory Data scientists are required to draw conclusions about a group, a.k.a population from a few samples of it because getting the entire population is intractable. This process of drawing samples is called sampling.","tags":["statistics","hypothesis testing","samples"],"title":"Sampling Theory and Distributions","type":"post"},{"authors":[],"categories":["systems"],"content":"Some Prerequisites What is a variable? A variable is a storage location for a value. Linux has environment variables. It can store strings, numbers , etc. just like the variables in C, C++, python, or any other programming language. It even has a scope, just like the variables in other programming languages! Based on scopes Linux environments variables can be classified into 2 different categories:\n Local Variables Global Variable  Local Variables Local variables are set by typing \u0026lt;variable_name\u0026gt;= \u0026lt;variable_value\u0026gt; (i.e without the export command). Local variables can only be accessed by the terminal where it is declared and not by any program even if it is run from the terminal itself.\nGlobal Variables Global variables are set by typing export \u0026lt;variable_name\u0026gt;= \u0026lt;variable_value\u0026gt;. The export command ensures that the variable be exported to any child process forked from that terminal. In short, it ensure that the variable set is global.\nUnderstanding the Difference There is a simple way to understand the difference between local and global environmnent variables.\nOpen a terminal\nexport global_var=\u0026quot;This is a global variable\u0026quot; local_var = \u0026quot;This is a local variable\u0026quot; echo $global_var echo $local_var  Now open tmuxa tmux session. Inside the session, type:\necho $global_var echo $local_var  You would notice that the local variable inside the tmux session contains no value whereas the global variable outputs the value that it has been assigned. You can see all the variables defined using the command \u0026lsquo;env\u0026rsquo;. A variable is unset by typing unset \u0026lt;variable_name\u0026gt;\nSome Important Paths in Linux: In this journey of learning how to install packages locally in linux, we need to about two very important global environment variables:\n PATH LD_LIBRARY_PATH  what is PATH? PATH is a list of colon separated directories in which the system looks for executable files. When we type a command the system looks for the executable binaries in each of these directories and executes them if found or else returns an error stating \u0026lsquo;command not found\u0026rsquo;. This lookup by the system occurs in a left-to-right fashion. That is,the system first looks for the executable in the left-most directory in the colon separated list and proceeds on to the next if not found. This sequence of lookup is necessary to understand because if you have two different executable files with the same name but at different locations(obviously!!), say /usr/local/bin/python and ./anaconda/bin/python , and you want to execute the ./anaconda/bin/python ,then you would have to put ./anaconda/bin(absolute location is preferred, this is a relative location) to the left of /usr/bin in the colon separated list of PATH.\nWhat is LD_LIBRARY_PATH? Similar to PATH, LD_LIBRARY_PATH stores the colon separated list of directories where the system should search for libraries first, before the standard set of directories. Just like PATH, the lookup in the LD_LIBRARY_PATH also occurs in a left-to-right manner.\nHands On!!! In this demo we will be installing GNU-aspell locally.\n Download the package from this link and extract it using tar -xf aspell-0.60.7.tar.gz command. Go inside the directory and type ./configure --help. This will list the options for changing the default setup locations among other things. Have a look at the options, especially the --prefix, --exec-prefix , --oldincludedir and --datadir options. We will be using these. Now run configure with the options containing the locations you desire. As an example let me share what I have done: ./configure --prefix='/home/anuragroy/local_install_dirs/' --exec-prefix='/home/anuragroy/local_install_dirs/' --oldincludedir='/home/anuragroy/local_install_dirs/include/' --datadir='/home/anuragroy/local_install_dirs/data/aspell/'. Here anuragroy is my username and local_install_dirs can be thought of as a substitute for the /usr/local directory. After the configuration is done type: {%highlight bash %} make; make clean ``` to install the package. What now remains is to set the required environment variables in the .bashrc file. I have added the following lines:  export PATH=\u0026quot;/home/anuragroy/local_install_dirs/bin:$PATH\u0026quot; export LD_LIBRARY_PATH=\u0026quot;/home/anuragroy/local_install_dirs/lib:$LD_LIBRARY_PATH\u0026quot; export C_INCLUDE_PATH=\u0026quot;/home/anuragroy/local_install_dirs/include:$C_INCLUDE_PATH\u0026quot; export CPLUS_INCLUDE_PATH=\u0026quot;/home/anuragroy/local_install_dirs/include:$CPLUS_INCLUDE_PATH\u0026quot; export MANPATH=\u0026quot;/home/anuragroy/local_install_dirs/data/aspell/man:$MANPATH\u0026quot;  And now aspell is installed!!! 😄\nNote: Python packages relying on local libraries(for example libraries located in ~/local_install_dirs/lib), headers(for example libraries located in ~/local_install_dirs/include) will return a cannot find.. error.There is a way around though \u0026mdash;clone the repository of the package and modify the relevant variables accordingly(like library_dirs for libraries and include_dirs for headers).\n","date":1568301113,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568301113,"objectID":"be5e05a51d48e2cca85e89a07a52e08a","permalink":"https://kiranpurohit.github.io/post/how_to_install_packages_locally_in_linux/","publishdate":"2019-09-12T20:41:53+05:30","relpermalink":"/post/how_to_install_packages_locally_in_linux/","section":"post","summary":"Some Prerequisites What is a variable? A variable is a storage location for a value. Linux has environment variables. It can store strings, numbers , etc. just like the variables in C, C++, python, or any other programming language.","tags":["Linux","systems","server accounts","hacks"],"title":"How to Install Packages Locally in Linux","type":"post"},{"authors":[],"categories":["Reinforcement Learning-An Introduction"],"content":"Introduction Reinforcement Learning is different from other machine learning in the aspect that it evaluates the actions rather than instructing than instructing the correct actions.\n  Purely evaluative feedback indicates how good an action is , but not whether it is best or worst action possible.\n  Purely instructive feedback indicates the correct action to take independent of the action already taken.\n  K-Armed Bandit Problem The k-armed bandit problem is similar to one-armed bandits, except that it has k levers instead of one. Here we are faced repeatedly with a choice among k different levers, or actions. Here the rewards are the payoffs for hitting the jackpot.\nIn the problem, each of the k actions has an expected or mean reward given that that action is selected; let us call this the value of that action.We denote the action selected on time step t as $A_t$ , and the corresponding reward as $R_t$. The value then of an arbitrary action $a$, denoted $q_∗(a)$, is the expected reward given that a is selected:\n$q_∗(a) = E[R_t | A_t = a]$\nWe denote the estimated value of action $a$ at time $t$ as $Q_t(a) \\approx q_*(a)$ .\nActions whose $Q_t$ value is the highest at time $t$, are called, greedy actions.All the other actions at time $t$ are called non-greedy actions.Selecting a greedy action is said to be exploitation whereas selecting a non-greedy action is said to be evaluation.Exploitation is the right thing to do to maximize the expected on the one step, but exploration may produce greater total reward in the long run.\nAction Value Methods So now we know that the true value of an action is the mean reward when the action is chosen.There can be many ways of calcuate this, one way can be:\n$$Q_t(a) = \\frac{\\text{sum of rewards when a is taken prior to t}}{\\text{number of times a is taken prior to t}} = \\frac{\\sum_{i=0}^{t-1} R_i \\cdot 1_{A_i = a}}{\\sum_{i=0}^{t-1} 1_{A_i = a}}$$\nwhere $1_predicate$ denotes the random variable that is $1$ if $predicate$ is true and $0$ if it is not. If the denominator is zero, then we instead de\u000cnote $Q_t(a)$ as some default value, such as $Q_1(a) = 0$ . As the denominator goes to in\u000cfnity, by the law of large numbers, $Q_t(a)$ converges to $q_*(a)$. We call this the *sample-average* method for estimating action values because each *estimate* is an average of the *sample* of relevant rewards.\nThe greedy actions selection method (a.k.a exploitation) can be represented as:\n$A_t = \\underset{x}{\\operatorname{argmax}}Q_t(a)$\nWhere $argmax_a$ denotes the value of $a$ at which the expressio that follows is maximized(with ties broken arbitrarily). A simple alternative to this purely greedy approach is a $\\varepsilon-greedy$ approach where with probability $\\varepsilon$ , select an action from the set of non-greedy actions unformly and randomly.\nIncremental Implementation We would now dive into the implementation of the above formulae to reinforcement learning problems. Lets concentrate on a single action $a$. Let $R_i$ denote the reward received after the $ith$ selection of this action.Let $Q_n$ denote the estimate of this action after it has been selected n-1 times. Then we can write:\n$$Q_n(a) = \\frac{R_1 + R_2 +\u0026hellip;+ R_{n-1}}{n-1}$$\nKeeping a record of all the rewards will be inefficient in terms of memory, so we would tweak the formula a little bit:\n $$ \\begin{align} Q_{n+1} \u0026 = \\frac{1}{n}\\sum_{i=1}^{n} R_i \\\\ \u0026 = \\frac{1}{n}\\bigl(R_n + \\sum_{i=1}^{n-1} R_i\\bigr) \\\\ \u0026 = \\frac{1}{n}\\bigl(R_n + (n-1)\\frac{1}{n-1}\\sum_{i=1}^{n-1} R_i\\bigr) \\\\ \u0026 = \\frac{1}{n}\\bigl(R_n + (n-1)Q_n\\bigr) \\\\ \u0026 = \\frac{1}{n}\\bigl(R_n + nQ_n - Q_n\\bigr) \\\\ \u0026 = Q_n + \\frac{1}{n}[R_n - Q_n] \\end{align} $$  A Simple Bandit Algorithm  $$ \\begin{align} \u0026 \\text{Initialize, for a } = 1 \\text{ to k}: \\\\ \u0026 \\quad Q(a) \\leftarrow 0 \\\\ \u0026 \\quad N(a) \\leftarrow 0 \\\\ \u0026 \\text{Repeat Forever:} \\\\ \u0026 \\quad A \\leftarrow \\begin{cases} \\underset{a}{\\operatorname{argmax}}Q(a) \\text{ with probability 1-} \\varepsilon \\text{ (breaking ties randomly)} \\\\ \\text{ a random action with probability } \\varepsilon \\\\ \\end{cases} \\\\ \u0026 R \\leftarrow bandit(a) \\\\ \u0026 N(A) \\leftarrow N(A) + 1 \\\\ \u0026 Q(A) \\leftarrow Q(A) + \\frac{1}{N(A)}[R - Q(A)] \\end{align} $$  The $\\frac{1}{N(A)}$ parameter (a.k.a StepSize) changes from time step to time step and can also be written as $\\alpha_{t}(a)$.\n$\\alpha_{t}(a)$ is any function that satisfies the following conditions :\n$\\sum_{t=1}^{\\infty}\\alpha_{t}(a) = \\infty \\text{ and } \\sum_{t=1}^{\\infty} \\alpha_{t}^2(a) \\lt \\infty $\nFor the time-being let us consider $\\alpha_t$ to be a constant (say $\\alpha \\epsilon (0,1]$ ). We can also write $Q_{n+1}$ in terms of $Q_1$:\n $$\\begin{align} Q_{n+1} \u0026 = Q_n + \\alpha [R_n - Q_n] \\\\ \u0026 = \\alpha R_n + (1 - \\alpha)Q_n \\\\ \u0026 = \\alpha R_n + (1 - \\alpha)[\\alpha R_n + (1 - \\alpha)Q_{n-1}] \\\\ \u0026 = \\alpha R_n + (1 - \\alpha)[\\alpha R_n + (1 - \\alpha)Q_{n-1}] \\\\ \u0026 = \\alpha R_n + (1 - \\alpha)\\alpha R_{n-1} + (1 - \\alpha)^2 Q_{n-1} \\\\ \u0026 = \\alpha R_n + (1 - \\alpha)\\alpha R_{n-1} + (1 - \\alpha)^2 \\alpha R_{n-2} + \\\\ \u0026 ... + (1 - \\alpha)^{n-1}\\alpha R_1 + (1 - \\alpha)^n Q_1 \\\\ \u0026 = (1 - \\alpha)^n Q_1 + \\sum_{i=1}^{n} \\alpha(1 - \\alpha)^{n-i}R_i \\\\ \\end{align}$$  Choosing a positive $Q_1(a)$ value helps the model to explore more and thus learn better in the long run. Upper-Confidence-Bound Action Selection Method $\\varepsilon$-greedy action selection method forces the non-greedy actions to be tried, but indiscriminately, with no preference to those that are nearly greedy. It would be better to select among the non-greedy actions according to their potential for actually being optimal, taking into account both how close their estimates are to being maximal and the uncertanities in those estimates.\nOne effective way of doing this is to select action as:\n$A_t = \\underset{a}{\\operatorname{argmax}}\\Bigl[Qt(a) + \\sqrt[\\leftroot{-2}\\uproot{2}c]{\\tfrac{\\log t}{N_t(a)}} \\Bigr]$\nwhere $\\log t$ denotes the natural logarithm of $t$ , $N_t(a)$ denotes the number of times that action $a$ has been selected prior to time $t$ and the number $ c \\gt 0$ controls the degree of exploration. If $N_t(a) = 0$, then $a$ is considered to be a maximizing action.\nThe idea of this method is that the square-root term is a measure of the uncertainity or variance in the measure of $a$'s value.Each time action $a$ is selected $N_t(a)$ increases by one and the contribution of the square-root term in selecting action $A_t$ is decreased.That means that if $a$ is chosen a lot of times then chances of it being selected depends mostly on $Q_t$, which should be the behaviour of our model, logically.\nGradient Bandit Algorithms In this section we consider learning a numerical preference $H_t(a)$ for each action $a$. The larger the preference more often that action is tken, but the preference has no interpretation in terms of reward.Since the relative preference is important we take softmax over all the preferences at time $t$ which we denote as $\\pi_{t}(a)$.\n$Pr{A_t=a} = \\frac{\\varepsilon^{H_t(a)}}{\\sum_{b=1}^{k} \\varepsilon^{H_t(b)}} = \\pi_{t}(a)$\nThere is a natural learning algorithm for this setting based on the idea of stochastic gradient ascent.On each step, after selecting the action $A_t$ and receiving the reward $R_t$, the preferences are updated by:\n $$\\begin{align} H_{t+1}(A_t) \u0026 = H_t(A_t) + \\alpha(R_t - \\bar R_t)(1 - \\pi_{t}(A_t)), \\text{ and } \\\\ H_{t+1}(a) \u0026 = H_t(a) - \\alpha(R_t - \\bar R_t)(\\pi_{t}(a)) \\text{ } \\forall a \\neq A_t \\\\ \\end{align}$$  where $\\alpha \\gt 0$ is step-size parameter, and $\\bar R_t \\in \\mathbb R$ is the average of all the rewards up throught and including time $t$, which can be computed incrementally.The $\\bar R_t$ serves as the baseline with which the reward is compared. If the reward is higher than the baseline, then the probability of taking $A_t$ in the future is increased, and if the reward is below baseline, then the probability is decreased.The non-selected actions move in the opposite direction.\nFor the represenation of the Bandit Gradient Algorithm as Stochastic Gradient Ascent please refer section-2.8(page 29) of the book.\nNote: This a summarization of Chapter 2 of the book: Reinforcement Learning: An Introduction ","date":1510225580,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510225580,"objectID":"b6e584931d0c7f581083e8c0281058b5","permalink":"https://kiranpurohit.github.io/post/rl_chapter2/","publishdate":"2017-11-09T16:36:20+05:30","relpermalink":"/post/rl_chapter2/","section":"post","summary":"Introduction Reinforcement Learning is different from other machine learning in the aspect that it evaluates the actions rather than instructing than instructing the correct actions.\n  Purely evaluative feedback indicates how good an action is , but not whether it is best or worst action possible.","tags":["Reinforcement Learning","Reinforcement Learning-An Introduction"],"title":"Multi-Armed Bandits","type":"post"},{"authors":[],"categories":["Reinforcement Learning-An Introduction"],"content":"Reinforcement Learning refers to a class of problems which involve learning what to do, i.e. how to map situations to actions so as to maximize a numerical signal.In an essential way these are closed-loop problems because the learning system\u0026rsquo;s actions influence its later inputs. Moreover, unlike supervised learning it is not shown exmaples of desired behaviors,but instead it discovers and learns actions which would yield the maximum reward.Reinforcement learning is also different from unsupervised learning,because the goal of a reinforcement learning problem is to maximize a reward signal and not to find a hidden structure from the data as in supervised learning.\nOne of the challenges exclusive to reinforcement learning problems, is the trade-off between exploitation and exploration. To obtain a lot of reward, a reinforcement learning agent must prefer actions that it has tried in the past and found to be effective in producing reward. But to discover such actions it has to explore new actions.In exploring there is always a risk of failing at the task.So neither exploitation nor exploration can be performed exclusively without failing.\nKey Elements A reinforcement learning system consists of the following main elements:\n  Policy: A policy defines the learning agent\u0026rsquo;s way of behaving at a given time.Put simply, a policy is a mapping from perceived states of the environment to actions to be taken when in those states.\n  Reward Signal: A reward signal is a numeric value which the environment sends to the agent at each step. In reinforcement learning an agent\u0026rsquo;s sole objective is to maximize this reward signal over the long run.Reward signals may be stochastic functions of the state of the environment and the actions taken. {% highlight note %} Note: The processes that generate reward signal must be un-alterable by the agent, otherwise the agent may change the problem altogether in its favour. {% endhighlight %}\n  Value Function: The Value function generates the value of a state. Value of a state is the total amount of reward an agent can expect to accumulate over the future , starting from that state.Values are different from rewards in the sense that rewards are generated directly by the environment, but values must be estimated and re-estimated from the sequences of observation an agent makes over its entire lifetime. Actions are chosen that bring about states of highest value.\n  Model : Here model refers to a model of the environment.This is something that mimics the behavior of the environment.Reinforcement learining methods that use models are called model based methods, as opposed to model-free methods that are explicitly trial and error learners viewed as almost the opposite of planning.\n  Note: This a summarization of Chapter 1 of the book: Reinforcement Learning: An Introduction ","date":1510211829,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510211829,"objectID":"ea6ad5bf737d43c82a18b9612e04cb46","permalink":"https://kiranpurohit.github.io/post/rl_chapter1/","publishdate":"2017-11-09T12:47:09+05:30","relpermalink":"/post/rl_chapter1/","section":"post","summary":"he Reinforcement Learning Problem","tags":["Reinforcement Learning","Reinforcement Learning-An Introduction"],"title":"What is Reinforcement Learning?","type":"post"},{"authors":[],"categories":["Deep Learning"],"content":"What is TensorBoard? TensorBoard is a module of Tensorflow that provides a suite of visualisation tools that help in understanding, debugging and optimize the model created in Tensorflow.\nInstalling TensorBoard TensorBoard is installed along with Tensorflow. It can also be installed as a standalone software from Standalone TensorBoard\nKey Concepts TensorBoard works by reading summary data from Tensorflow event files which is generated by tensorflow.\nTensorflow creates a computational graph of the neural network model implemented.This model is then stored as a graph using the summary method.The name field in the Tensorflow variables, placeholders, operations, and name_scopes are used to annotate the nodes in the graph. These graphs are written to files and stored in a directory indicated in the summary.FileWriter method.We can select which nodes to be included in the graph using the summary.merge method. In order to select all the nodes to be included in the graph by using the summary.merge_all method.This summary (in the form of a protocol buffer) is added to the event file using the add_summary method.\n#Although the model in this code-segment will not converge, #this is just to show how tensorflow creates and saves summaries #in event files. import tensorflow as tf import numpy as np N = 5 x = tf.placeholder(tf.float32, shape=[N,1],name='X') y = tf.placeholder(tf.float32, shape=[N,N],name='y') with tf.name_scope('fc_layer'): W = tf.Variable(tf.truncated_normal([1,N], stddev=0.1), name='W') b = tf.Variable(tf.constant(0.1,shape=[N]),name='b') tf.summary.histogram('weights',W) #values of W will be shown as a histogram plot tf.summary.histogram('biases',b) #values of W will be shown as a histogram plot y_ = tf.matmul(x,W) + b with tf.name_scope('loss_func'): tf.summary.scalar('loss',0.05) sess = tf.Session() merged_summary = tf.summary.merge_all() writer = tf.summary.FileWriter(\u0026quot;./graphs/\u0026quot;, graph=sess.graph) sess.run(tf.global_variables_initializer()) s = sess.run(merged_summary,feed_dict={x:np.ones((N,1)),y:np.ones((N,N))}) i = 1 writer.add_summary(s,i) ```python ## Running TensorBoard Now that the event files have been created and stored in the directory[./graphs], running tensorboard with logdir pointing to the directory where the event files have been stored will give us a visualization of the model in the web browser. ```python tensorboard --logdir=./graphs  ","date":1510133984,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510133984,"objectID":"9d9573be70ee235f817272d6593eaaf0","permalink":"https://kiranpurohit.github.io/post/tensorboard_basics/","publishdate":"2017-11-08T15:09:44+05:30","relpermalink":"/post/tensorboard_basics/","section":"post","summary":"Visualing Tensorflow Models","tags":["TensorBoard","Tensorflow","Python","Deep learning","Neural Networks"],"title":"TensorBoard Basics","type":"post"},{"authors":[],"categories":["Deep Learning"],"content":"What is Tensorflow? Tensorflow is an open source software for machine learning developed by Google.Tensorflow, as one can get from its name, mainly handles matrices(or tensors), its mathematical operations and differentiation efficiently.It is just like Theano but with some extra features like it can be used on distributed systems.\nInstalling Tensorflow Installing tensorflow \u0026gt;= 1.1.0 can be done using python-pip\npip install --upgrade tensorflow # for the CPU only version pip install --upgrade tensorflow-gpu # for the GPU version  Key-Components Tensorflow works by first creating a computational graph resembling the model we wish to run and then executing it. A program written using tensorflow must consist of the following components:\n Variables: variables in tensorflow are in memory buffers containing tensors,but unlike normal tensors that live only for a single execution of a graph, variables values live as long as the session exists.Variables value cease to exist after the session is closed. Tensorflow has the option of saving variables\u0026rsquo; value to disk and restoring them for later use.Variables must be initialized before executing a graph for first time. During training operation variables get updated by default.Tensorflow variables are created using tf.Variable().We can keep a variable unchanged by explicitly setting its trainable parameter to false.  \u0026gt;\u0026gt;\u0026gt; import tensorflow as tf \u0026gt;\u0026gt;\u0026gt; # Declaring a tensoflow Variable \u0026gt;\u0026gt;\u0026gt; W = tf.Variable(tf.random_uniform([2,3],stddev=0.5), # same a numpy.random.uniform name='weight') # name of the variable in the computational graph \u0026gt;\u0026gt;\u0026gt; # Setting variable b to non -trainable \u0026gt;\u0026gt;\u0026gt; b = tf.Variable(tf.zeros([1]), # same as numpy.zeros name='b', trainable=False) \u0026gt;\u0026gt;\u0026gt; s = tf.Session() # session created \u0026gt;\u0026gt;\u0026gt; s.run(tf.initialize_all_variables()) # To initialize all the variables present in the current session \u0026gt;\u0026gt;\u0026gt; s.run(tf.initialize_variables(W)) # To only initialize W and not b   Placeholders: A placeholder can be thought of as a variable to which we can assign data at a later step.It is populated every single time a computational graph is run.A placeholder usually holds the input values to a model.Placeholder is created in tensorflow using tf.placeholder().Values in placeholders are entered using a feed_dict argument.  \u0026gt;\u0026gt;\u0026gt; import tensorflow as tf \u0026gt;\u0026gt;\u0026gt; # Declaring a tensoflow Variable \u0026gt;\u0026gt;\u0026gt; W = tf.Variable(tf.random_uniform([2,3],stddev=0.5), # same a numpy.random.uniform name='weight') # name of the variable in the computational graph \u0026gt;\u0026gt;\u0026gt; # Setting variable b to non -trainable \u0026gt;\u0026gt;\u0026gt; b = tf.Variable(tf.zeros([3]), # same as numpy.zeros name='b', trainable=False) \u0026gt;\u0026gt;\u0026gt; x = tf.placeholder(tf.float32, name='x', shape=[None, 2]) # defining a placeholder named x \u0026gt;\u0026gt;\u0026gt; # of type float32 and shape [None ,2] (None, i.e. any number of rows) \u0026gt;\u0026gt;\u0026gt; y = tf.add(tf.matmul(x,W), b) # operation x.W + b \u0026gt;\u0026gt;\u0026gt; s = tf.Session() # session created \u0026gt;\u0026gt;\u0026gt; s.run(tf.initialize_all_variables()) # To initialize all the variables present in the current session \u0026gt;\u0026gt;\u0026gt; s.run(y,feed_dict={x:[[1., 2.]]} # placeholder x feeded with value    Operations: Operations in tensoflow are functions which applies some transformations to tensors on the computational graph. Like Variables and placeholders tensorflow operations can also be named for easy identification in the computational graph.An operation may consist of multiple kernels, for different types of devices.For example, an operation may have seperate CPU and GPU kernels so that it can be excuted more efficiently on GPU.In the previous example tf.matmul() and tf.add() are two operations.As it relevant from the above example , tensorflow operations can be nested.\n  Sessions: A tensorflow session is responsible for interacting with the computational graph thus created and make necessary arrangements for execution of the graph.It allocates resources required by the computational graph and holds the values of variables.Tensorflow session object(say sess) is created using the tf.Session() class.Finally we can the computational graph or a subpart of it using the sess.run() method.All sess.run does is identify all the dependencies that compose the relevant subgraph, ensure that all the placeholder variables in the concerned subgraph are filled using feed_dict,and then start executing the subgraph.\n  ","date":1499270158,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499270158,"objectID":"188d7ff037094dc9e379cb3359349adc","permalink":"https://kiranpurohit.github.io/post/tensorflow_basics/","publishdate":"2017-07-05T21:25:58+05:30","relpermalink":"/post/tensorflow_basics/","section":"post","summary":"Getting Started With Tensorflow","tags":["Tensorflow","Python","Deep learning","Neural Networks"],"title":"Tensorflow Basics","type":"post"},{"authors":[],"categories":["coding guidelines by NASA programmer"],"content":"In the paper The Power of Ten-Rules for Developing Safety Critical Code the author has stated 10 rules adhering to which will make one a good programmer.\nThe author chosed C as the language for writing safety critical code because of the extensive tool support for this language including:\n  Strong source code analyzers like valgrind\n  debuggers like gdb\n  stable compilers\n  Test support tools\n  Following are the 10 rules the author wants to emphasize upon:\n   Rule: Restrict all code to very simple control flow constructs – do not use goto statements, setjmp or longjmp constructs, and direct or indirect recursion.\n   The author says to restrict all code to very simple control flow constructs because it enhances code clarity. Now asking not to use recursion might look suprising but this is also used to improve code clarity.(Remember that every recursive solution has an equivalent iterative solution.)\n   Rule: All loops must have a fixed upper-bound. It must be trivially possible for a checking tool to prove statically that a preset upper-bound on the number of iterations of a loop cannot be exceeded. If the loop-bound cannot be proven statically, the rule is considered violated.\n   I think this rule does not need any explanations except for the fact that this rule is not applicable to iterations that are non-terminating(e.g. in a process scheduler).In those cases we need to statistically prove that no upper-bound exists for such a problem.\n   Rule: Do not use dynamic memory allocation after initialization.\n   This rule is given because memory allocators and garbage collectors often have unpredictable behaviour which might cause a coding error.\n   Rule: No function should be longer than what can be printed on a single sheet of paper in a standard reference format with one line per statement and one line per declaration. Typically, this means no more than about 60 lines of code per function.\n   This rule is given to ensure modularity and enhance readability. The author states in his rationale that \u0026ldquo;excessively long functions are often a sign of poorly structured code.\u0026rdquo;\n   Rule: The assertion density of the code should average to a minimum of two assertions per function. Assertions are used to check for anomalous conditions that should never happen in real-life executions. Assertions must always be side-effect free and should be defined as Boolean tests. When an assertion fails, an explicit recovery action must be taken, e.g., by returning an error condition to the caller of the function that executes the failing assertion. Any assertion for which a static checking tool can prove that it can never fail or never hold violates this rule. (I.e., it is not possible to satisfy the rule by adding unhelpful “assert(true)” statements.)\n   This is because assertions make it easier to find bugs in the code.They are also \u0026ldquo;side effect free\u0026rdquo; which means that they can be selectively disabled without changing the behaviour of the code.\n   Rule: Data objects must be declared at the smallest possible level of scope.\n   This rule uses the principle of data hiding. Many errors occur in programs because of wrong referencing of objects in the code. So if we reduce the scope of refer the object we will be able to find mistake in referencing in a lesser amount of time.\n   Rule: The return value of non-void functions must be checked by each calling function, and the validity of parameters must be checked inside each function.\n   According to the author this is one of the most important rule because sometimes return value of a function helps us to find error in the code.For e.g. lets say we have problem in closing a file in C.We can do two things here: 1. The time consuming one - Put various printf and assertion statements trying to find where he error is occurring. 2. The time saving one - Check the return value of the function close() and lookup it\u0026rsquo;s errno.\n   Rule: The use of the preprocessor must be limited to the inclusion of header files and simple macro definitions. Token pasting, variable argument lists (ellipses), and recursive macro calls are not allowed. All macros must expand into complete syntactic units. The use of conditional compilation directives is often also dubious, but cannot always be avoided. This means that there should rarely be justification for more than one or two conditional compilation directives even in large software development efforts, beyond the standard boilerplate that avoids multiple inclusion of the same header file. Each such use should be flagged by a tool-based checker and justified in the code.\n    Rule: The use of pointers should be restricted. Specifically, no more than one level of dereferencing is allowed. Pointer dereference operations may not be hidden in macro definitions or inside typedef declarations. Function pointers are not permitted.\n   Pointers often make codes hard to analyze especially by static analyzers.As the author says \u0026quot; Function pointers, can seriously restrict the types of checks that can be performed by static analyzers and should only be used if there is a strong justification for their use, and ideally alternate means are provided to assist tool-based checkers determine flow of control and function call hierarchies\u0026rdquo;.Function pointers make it impossible for a tool to prove absence of recursion.\n  \u0026gt; Rule: All code must be compiled, from the first day of development, with all \u0026gt; compiler warnings enabled at the compiler’s most pedantic setting. All code must \u0026gt; compile with these setting without any warnings. All code must be checked daily with \u0026gt; at least one, but preferably more than one, state-of-the-art static source code analyzer \u0026gt; and should pass the analyses with zero warnings.   ","date":1472877265,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472877265,"objectID":"a188ef874cecd7c14e0ec515e6d85f9c","permalink":"https://kiranpurohit.github.io/post/programming_guidelines/","publishdate":"2016-09-03T10:04:25+05:30","relpermalink":"/post/programming_guidelines/","section":"post","summary":"How to write good code","tags":["coding","C","techniques"],"title":"Programming Guidelines","type":"post"},{"authors":[],"categories":["byte ordering in the network layer"],"content":"While studying networks I came across two system calls namely\n ntoh(s/l) hton(s/l)  Both of the above are related to byte ordering done in the network layer\nntoh(s/l) It is used by host to convert a packet from network byte order to host byte order. (s for short and l for long).\nhton(s/l) It is used by host before sending a packet to the network. This function converts a packet in host byte order to network byte order. (s for short and l for long).\nI am not writing the example syntaxes of the above functions because you can easilly get them in the internet.\nWhat will happen if I do not use the above functions? Well this depends upon the endianess of your machine. If your machine follows Big Endian then you can do away with the functions, but if your pc follows little endian then you may get erroneous results. This is because almost all network protocols follow big endian.\nHow to check endianness of your pc  You can either use the following command  lscpu  and check the endianness of your pc\n You can also use the following cpp code to check the endianness of your pc  # include \u0026lt;stdio.h\u0026gt; int main(void) { unsigned long i = 1; int *c = (int*)\u0026amp;i; if (c[0]==1) printf(\u0026quot;Little endian\\n\u0026quot;); else if(c[1]==1) printf(\u0026quot;Big endian\\n\u0026quot;); else printf(\u0026quot;Unknown Endianness\\n\u0026quot;); }  ","date":1472376267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472376267,"objectID":"51d86545ad1863bcd7b54f65807873ae","permalink":"https://kiranpurohit.github.io/post/endianness_of_your_pc/","publishdate":"2016-08-28T14:54:27+05:30","relpermalink":"/post/endianness_of_your_pc/","section":"post","summary":"While studying networks I came across two system calls namely\n ntoh(s/l) hton(s/l)  Both of the above are related to byte ordering done in the network layer\nntoh(s/l) It is used by host to convert a packet from network byte order to host byte order.","tags":["networks","c++"],"title":"How to determine the Endianness of your PC","type":"post"}]